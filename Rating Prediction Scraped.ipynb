{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213fde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required library\n",
    "import selenium\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException,ElementClickInterceptedException, ElementNotVisibleException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e89acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_template(search_term,page_no=1):\n",
    "    \"\"\"Generate a URL for search Term with page number\"\"\"\n",
    "    \n",
    "    search_term = search_term.replace(' ','+')\n",
    "    template = f'https://www.amazon.in/s?k={search_term}&page={page_no}&qid=1623864210&ref=sr_pg_{page_no}'\n",
    "    \n",
    "    return template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e302058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that generated URL with the search tearm\n",
    "def get_url():\n",
    "    Itms = ['laptops', 'Phones', 'Headphones', 'smart watches', 'Professional Cameras', 'Printers', 'scanners', 'keyboard', 'monitors', 'Home theater', 'router']\n",
    "    URL = []     \n",
    "    for i in Itms:\n",
    "        for j in range(1,15):\n",
    "            URL.append(get_template(i,j))\n",
    "    return URL   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2491d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function that scraps the URL of the front page of the reviews and rattings with the search tearm.\n",
    "def get_review_url(): \n",
    "    \n",
    "    hreff = []\n",
    "    driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "    driver.maximize_window()\n",
    "\n",
    "    URL = get_url()\n",
    "    for k in URL:\n",
    "        driver.get(k) #Opening with the URL template\n",
    "\n",
    "        for l in driver.find_elements(By.XPATH,\"//a[@class = 'a-link-normal']\"):\n",
    "            hreff.append(l.get_attribute(\"href\"))   \n",
    "    return hreff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37425266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "href = get_review_url()\n",
    "def get_review(): #the function that scraps the URL of all the reviews and rattings\n",
    "    \n",
    "    driver = webdriver.Chrome(r\"chromedriver.exe\") #Calling the Web Driver\n",
    "    driver.maximize_window()\n",
    "    rattings = []\n",
    "    review = []\n",
    "\n",
    "    for i in href:\n",
    "        driver.get(i) #Opening with the URL template\n",
    "        \n",
    "        try: #scraping the URL of the full review pages\n",
    "            link = driver.find_element(By.XPATH,\"//a[@data-hook='see-all-reviews-link-foot']\")\n",
    "            link = link.get_attribute(\"href\")\n",
    "            link= link.split('ref=cm')[0]\n",
    "        except:\n",
    "            pass     \n",
    "        \n",
    "        for i in range(1,5): #Scraping Reviews and Rattings\n",
    "            l1= f'ref=cm_cr_getr_d_paging_btm_next_{i}?ie=UTF8&reviewerType=all_reviews&pageNumber={i}'\n",
    "            l = link+ l1 \n",
    "            \n",
    "            \n",
    "            driver.get(l)\n",
    "            \n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            results = soup.find_all('div',{'class' : 'a-section celwidget'})\n",
    "        \n",
    "            for item in results:\n",
    "                    try:\n",
    "                        rev = item.find('span', {'data-hook': \"review-body\"})\n",
    "                        atag = item.find(['a'], class_ = \"a-link-normal\")\n",
    "                        if rev.span.text.replace('\\n','').strip() and atag['title'][0]:\n",
    "                            review.append(rev.span.text.replace('\\n','').strip())\n",
    "                            rattings.append(atag['title'][0])\n",
    "                        else:\n",
    "                            break\n",
    "                    except:\n",
    "                        break\n",
    "       \n",
    "    driver.close()\n",
    "    \n",
    "    rating = pd.DataFrame({'Rattings':rattings, \"Review\": review})\n",
    "    \n",
    "    #saving the dataframe in csv\n",
    "    rating.to_csv(\"Rattings1.csv\",index=False) #Creating CSV\n",
    "    \n",
    "    return rat\n",
    "\n",
    "\n",
    "Rating = get_review()\n",
    "Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1913539",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating.to_csv(\"Ratings_scraped.csv\",index=False)# saving Data frame as CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32c8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
